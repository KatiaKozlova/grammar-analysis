{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatiaKozlova/grammar-analysis/blob/main/grammar_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "KdmRZtwANjMn",
        "outputId": "ed39bb7b-945f-4d35-f2bc-61016108227b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.6.2-py3-none-any.whl (36 kB)\n",
            "Collecting Pillow>=9.1\n",
            "  Downloading Pillow-9.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 12.3 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20220319\n",
            "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting Wand>=0.6.7\n",
            "  Downloading Wand-0.6.7-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 40.5 MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20220319->pdfplumber) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six==20220319->pdfplumber) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six==20220319->pdfplumber) (2.21)\n",
            "Installing collected packages: cryptography, Wand, Pillow, pdfminer.six, pdfplumber\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.1.1 Wand-0.6.7 cryptography-37.0.2 pdfminer.six-20220319 pdfplumber-0.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libmagickwand-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AycFHA1lE45j",
        "outputId": "8a0a31ef-cf06-4275-8f54-18b56481ef72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono ghostscript gir1.2-freedesktop\n",
            "  gir1.2-gdkpixbuf-2.0 gir1.2-rsvg-2.0 gsfonts imagemagick-6-common\n",
            "  libcairo-script-interpreter2 libcairo2-dev libcupsfilters1 libcupsimage2\n",
            "  libdjvulibre-dev libdjvulibre-text libdjvulibre21 libgdk-pixbuf2.0-dev\n",
            "  libgs9 libgs9-common libijs-0.35 libjbig2dec0 liblcms2-dev liblqr-1-0\n",
            "  liblqr-1-0-dev libmagickcore-6-arch-config libmagickcore-6-headers\n",
            "  libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra libmagickcore-6.q16-dev\n",
            "  libmagickwand-6-headers libmagickwand-6.q16-3 libmagickwand-6.q16-dev\n",
            "  libpixman-1-dev librsvg2-dev libwmf-dev libwmf0.2-7 libxcb-shm0-dev\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto ghostscript-x libcairo2-doc inkscape libjxr-tools librsvg2-doc\n",
            "  libwmf-doc libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono ghostscript gir1.2-freedesktop\n",
            "  gir1.2-gdkpixbuf-2.0 gir1.2-rsvg-2.0 gsfonts imagemagick-6-common\n",
            "  libcairo-script-interpreter2 libcairo2-dev libcupsfilters1 libcupsimage2\n",
            "  libdjvulibre-dev libdjvulibre-text libdjvulibre21 libgdk-pixbuf2.0-dev\n",
            "  libgs9 libgs9-common libijs-0.35 libjbig2dec0 liblcms2-dev liblqr-1-0\n",
            "  liblqr-1-0-dev libmagickcore-6-arch-config libmagickcore-6-headers\n",
            "  libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra libmagickcore-6.q16-dev\n",
            "  libmagickwand-6-headers libmagickwand-6.q16-3 libmagickwand-6.q16-dev\n",
            "  libmagickwand-dev libpixman-1-dev librsvg2-dev libwmf-dev libwmf0.2-7\n",
            "  libxcb-shm0-dev poppler-data\n",
            "0 upgraded, 38 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 31.0 MB of archives.\n",
            "After this operation, 91.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.12 [60.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6-arch-config amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [25.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6-headers all 8:6.9.7.4+dfsg-16ubuntu6.12 [47.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [1,621 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6-headers all 8:6.9.7.4+dfsg-16ubuntu6.12 [10.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [292 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.4 [49.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.4 [561 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [62.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-dev amd64 3.5.27.1-8ubuntu0.4 [2,382 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblcms2-dev amd64 2.9-1ubuntu0.1 [9,096 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0-dev amd64 0.4.2-2.1 [69.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.36.11-2 [7,748 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-rsvg-2.0 amd64 2.40.20-2ubuntu0.2 [3,764 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-dev amd64 2.36.11-2 [46.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 librsvg2-dev amd64 2.40.20-2ubuntu0.2 [10.7 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf-dev amd64 0.2.8.4-12 [172 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-dev amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [974 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-dev amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [290 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-dev all 8:6.9.7.4+dfsg-16ubuntu6.12 [1,368 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.16 [5,093 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.16 [2,265 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.16 [51.3 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Fetched 31.0 MB in 2s (14.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../01-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickcore-6-arch-config:amd64.\n",
            "Preparing to unpack .../02-libmagickcore-6-arch-config_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickcore-6-arch-config:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickcore-6-headers.\n",
            "Preparing to unpack .../03-libmagickcore-6-headers_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n",
            "Unpacking libmagickcore-6-headers (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../04-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n",
            "Preparing to unpack .../05-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickwand-6-headers.\n",
            "Preparing to unpack .../06-libmagickwand-6-headers_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n",
            "Unpacking libmagickwand-6-headers (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n",
            "Preparing to unpack .../07-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../08-libdjvulibre-text_3.5.27.1-8ubuntu0.4_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../09-libdjvulibre21_3.5.27.1-8ubuntu0.4_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Selecting previously unselected package libwmf0.2-7:amd64.\n",
            "Preparing to unpack .../10-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n",
            "Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n",
            "Preparing to unpack .../11-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libdjvulibre-dev:amd64.\n",
            "Preparing to unpack .../12-libdjvulibre-dev_3.5.27.1-8ubuntu0.4_amd64.deb ...\n",
            "Unpacking libdjvulibre-dev:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Selecting previously unselected package liblcms2-dev:amd64.\n",
            "Preparing to unpack .../13-liblcms2-dev_2.9-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblcms2-dev:amd64 (2.9-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblqr-1-0-dev:amd64.\n",
            "Preparing to unpack .../14-liblqr-1-0-dev_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0-dev:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "Preparing to unpack .../15-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\n",
            "Preparing to unpack .../16-gir1.2-gdkpixbuf-2.0_2.36.11-2_amd64.deb ...\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package gir1.2-rsvg-2.0:amd64.\n",
            "Preparing to unpack .../17-gir1.2-rsvg-2.0_2.40.20-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking gir1.2-rsvg-2.0:amd64 (2.40.20-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-dev.\n",
            "Preparing to unpack .../18-libgdk-pixbuf2.0-dev_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "Preparing to unpack .../19-libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../20-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../21-libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../22-libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package librsvg2-dev:amd64.\n",
            "Preparing to unpack .../23-librsvg2-dev_2.40.20-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-dev:amd64 (2.40.20-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libwmf-dev.\n",
            "Preparing to unpack .../24-libwmf-dev_0.2.8.4-12_amd64.deb ...\n",
            "Unpacking libwmf-dev (0.2.8.4-12) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-dev:amd64.\n",
            "Preparing to unpack .../25-libmagickcore-6.q16-dev_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-dev:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-dev:amd64.\n",
            "Preparing to unpack .../26-libmagickwand-6.q16-dev_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-dev:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package libmagickwand-dev.\n",
            "Preparing to unpack .../27-libmagickwand-dev_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n",
            "Unpacking libmagickwand-dev (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../28-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../29-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../30-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../31-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../32-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../33-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.16_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../34-libgs9_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../35-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../36-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../37-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up liblcms2-dev:amd64 (2.9-1ubuntu0.1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up libmagickcore-6-arch-config:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up gir1.2-rsvg-2.0:amd64 (2.40.20-2ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libmagickcore-6-headers (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Setting up libwmf-dev (0.2.8.4-12) ...\n",
            "Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up liblqr-1-0-dev:amd64 (0.4.2-2.1) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Setting up libmagickwand-6-headers (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libdjvulibre-dev:amd64 (3.5.27.1-8ubuntu0.4) ...\n",
            "Setting up librsvg2-dev:amd64 (2.40.20-2ubuntu0.2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libmagickcore-6.q16-dev:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libmagickwand-6.q16-dev:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Setting up libmagickwand-dev (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyenchant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXqrLK9KeGEL",
        "outputId": "5bdbd6b1-31b3-45a2-ed41-4402a4960cde"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libenchant1c2a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKz_o56Xg-MS",
        "outputId": "ffddaa11-fcc4-4b04-c486-9632cbc6dfd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,312 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtext-iconv-perl amd64 1.7-5build6 [13.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaspell15 amd64 0.60.7~20110707-4ubuntu0.2 [310 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 emacsen-common all 2.0.8 [17.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dictionaries-common all 1.27.2 [186 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 aspell amd64 0.60.7~20110707-4ubuntu0.2 [87.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 aspell-en all 2017.08.24-0-0.1 [298 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-en-us all 1:2017.08.24 [168 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhunspell-1.6-0 amd64 1.6.2-1 [154 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libenchant1c2a amd64 1.6.0-11.1 [64.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 enchant amd64 1.6.0-11.1 [12.2 kB]\n",
            "Fetched 1,312 kB in 1s (1,528 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 157545 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install myspell-es"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc00bPk9_OvT",
        "outputId": "776f6399-5b5f-4359-9de6-25c39e074a01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  hunspell libreoffice-core | openoffice.org-hunspell | openoffice.org-core\n",
            "  iceape-browser | iceweasel | icedove\n",
            "The following NEW packages will be installed:\n",
            "  myspell-es\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 201 kB of archives.\n",
            "After this operation, 1,004 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 myspell-es all 1.11-14 [201 kB]\n",
            "Fetched 201 kB in 1s (358 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package myspell-es.\n",
            "(Reading database ... 157959 files and directories currently installed.)\n",
            "Preparing to unpack .../myspell-es_1.11-14_all.deb ...\n",
            "Unpacking myspell-es (1.11-14) ...\n",
            "Setting up myspell-es (1.11-14) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install myspell-de-de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5UJ7j08_RrD",
        "outputId": "11c30074-fa0f-4745-81d1-74dc559226cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  hunspell-de-de\n",
            "Suggested packages:\n",
            "  hunspell libreoffice-writer\n",
            "The following NEW packages will be installed:\n",
            "  hunspell-de-de myspell-de-de\n",
            "0 upgraded, 2 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 286 kB of archives.\n",
            "After this operation, 1,175 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-de-de all 20161207-4 [284 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 myspell-de-de all 20161207-4 [2,708 B]\n",
            "Fetched 286 kB in 1s (404 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package hunspell-de-de.\n",
            "(Reading database ... 158008 files and directories currently installed.)\n",
            "Preparing to unpack .../hunspell-de-de_20161207-4_all.deb ...\n",
            "Unpacking hunspell-de-de (20161207-4) ...\n",
            "Selecting previously unselected package myspell-de-de.\n",
            "Preparing to unpack .../myspell-de-de_20161207-4_all.deb ...\n",
            "Unpacking myspell-de-de (20161207-4) ...\n",
            "Setting up hunspell-de-de (20161207-4) ...\n",
            "Setting up myspell-de-de (20161207-4) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install myspell-fr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTN--xrB-BIx",
        "outputId": "d47a0814-7949-4fca-d438-7e65f286ca68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  myspell-fr\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 170 kB of archives.\n",
            "After this operation, 821 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 myspell-fr all 1.4-27 [170 kB]\n",
            "Fetched 170 kB in 1s (314 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package myspell-fr.\n",
            "(Reading database ... 158023 files and directories currently installed.)\n",
            "Preparing to unpack .../myspell-fr_1.4-27_all.deb ...\n",
            "Unpacking myspell-fr (1.4-27) ...\n",
            "Setting up myspell-fr (1.4-27) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS-luKwhPbls",
        "outputId": "dde54fb7-51b4-4935-cdff-e7f6f7cd99fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ca1cJo8-No-d"
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import enchant\n",
        "import re \n",
        "import csv\n",
        "import os\n",
        "import json\n",
        "import string\n",
        "import shutil \n",
        "import requests\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from flask import Flask, send_file\n",
        "from flask import render_template, request, redirect, url_for\n",
        "from werkzeug.utils import secure_filename"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_en = enchant.Dict('en')\n",
        "d_de = enchant.Dict('de_DE')\n",
        "d_fr = enchant.Dict('fr')\n",
        "d_es = enchant.Dict('es')"
      ],
      "metadata": {
        "id": "dApAai37h1U-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tables(pg, nmng, pth, p_num):  # function for table extraction\n",
        "    table_settings = {  # settings for explicit borders \n",
        "        \"vertical_strategy\": \"lines\",\n",
        "        \"horizontal_strategy\": \"lines\",\n",
        "    }\n",
        "    flag = 0\n",
        "    table = pg.extract_table(table_settings)  # extraction of the biggest table on a page \n",
        "    if table:\n",
        "        flag = 0\n",
        "        my_df = pd.DataFrame(table[1:], columns=table[0])  # extracted table to DataFrame\n",
        "        with open(pth + '/' + str(p_num + 1) + '_' + nmng[0][2].replace(':', '.') + '._' + nmng[0][3].replace('/', '').replace('*', '').replace('<', '').replace(':', '.').strip() + '.csv', 'w+', encoding='utf-8') as csv_table:\n",
        "            my_df.to_csv(csv_table, index=False)  # saving DataFrame in CSV\n",
        "        if len(re.findall(r',-[^-,]|[^-,]-,|[^-,]-\\s|\\s-[^-,]|,=|=,|[^\\s]=\\s|\\s=[^\\s]',  my_df.to_csv(index=False))) < 3:  # cheking for morphemes in a cell\n",
        "            os.remove(pth + '/' + str(p_num + 1) + '_' + nmng[0][2].replace(':', '.') + '._' + nmng[0][3].replace('/', '').replace('*', '').replace('<', '').replace(':', '.').strip() + '.csv')  # delete if no morphemes\n",
        "        else:\n",
        "            flag = 1\n",
        "        if flag == 1:  # if morphological table is found\n",
        "            tab = pg.debug_tablefinder(table_settings)\n",
        "            for req_table in tab.tables:\n",
        "                if req_table.extract()[0] == table[0]:\n",
        "                    cropped = pg.within_bbox(req_table.bbox)  # crop page\n",
        "                    img = cropped.to_image(resolution=200)\n",
        "                    # save cropped page as image\n",
        "                    img.save(pth + '/' + str(p_num + 1) + '_' + nmng[0][2].replace(':', '.') + '._' + nmng[0][3].replace('/', '').replace('*', '').replace('<', '').replace(':', '.').strip() + '.jpeg')\n",
        "                    break"
      ],
      "metadata": {
        "id": "1hBuZwvYQi47"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_examples_tables(name): \n",
        "    path = name.split('.')[0]\n",
        "    if not os.path.exists(path):  # folder creation\n",
        "        os.mkdir(path)\n",
        "    with pdfplumber.open(name) as pdf:\n",
        "        examples_dic = {}\n",
        "        for p in range(len(pdf.pages)):\n",
        "            page = pdf.pages[p]\n",
        "            text = page.extract_text()  # text extraction\n",
        "            # IMG-finder\n",
        "            examples = re.findall(r\"\\n((\\s*?((\\(?(\\d+([\\.\\-:]\\d+){0,2}|\\d*[a-z])\\)|\\d+:|\\[\\d+\\]|\\d+([a-z]|\\-\\d+)?\\.)(\\s+?[a-z]\\.|\\s+?\\([a-z]\\))?)|(\\s*?[a-z]\\.))((.*?)\\n){2,5}\\s*?((‘.*’)|(“.*”)|(„.*‟)|('.*')|(\\\".*\\\")|(`.*')|(«.*»)))\", text)\n",
        "            # find all the tables' names\n",
        "            naming = re.findall(r'(^|\\n)\\s*(Table|TABLE|Tableau|TABLEAU|Cuadro|CUADRO)\\s+(\\d+)(.*?)\\n', text)\n",
        "            nmbr = len(naming)\n",
        "            if nmbr != 0:  # there is a table name on a page\n",
        "                extract_tables(page, naming, path, p)  # table extraction (see above)\n",
        "            for example in examples:  # for each example\n",
        "                number = None\n",
        "                if example:\n",
        "                    letter = ''\n",
        "                    t = example[0].strip()\n",
        "                    t = re.sub('\\t', ' ', t)\n",
        "                    clear = t.split('\\n')\n",
        "                    for i in range(len(clear)):\n",
        "                        line = clear[i]\n",
        "                        if '-' not in line and '=' not in line and '–' not in line:  # omittimg first lines without glossing\n",
        "                            continue\n",
        "                        else:\n",
        "                            break\n",
        "                    t = '\\n'.join(clear[i:])\n",
        "                    # trying to find example's number\n",
        "                    if t.startswith('('):  # '(12)'-like\n",
        "                        number = t.split(')')[0].strip('(')\n",
        "                        txt = re.sub(r'\\(?(\\d+([\\.\\-:]\\d+){0,2}|\\d*[a-z])\\)|\\d+:|\\[\\d+\\]|\\d+([a-z]|\\-\\d+)?\\.', '', t).strip()\n",
        "                         # trying to find example's sub-number\n",
        "                        if '.' in txt.split('\\n')[0].strip().strip('.'):  # '(12) a.'-like\n",
        "                            letter = txt.split('\\n')[0].strip().strip('.').split('.')[0]\n",
        "                            letter = letter.strip()\n",
        "                        elif ')' in txt.split('\\n')[0].strip().split('(')[0]: # '(12) (a)'-like\n",
        "                            letter = txt.split('\\n')[0].strip().split('(')[0].split(')')[0]\n",
        "                            letter = letter.strip()\n",
        "                    elif t.startswith('['):  # '[12]'-like\n",
        "                        number = t.split(']')[0].strip('[')\n",
        "                    elif ')' in t.split('\\n')[0].strip().split('(')[0]:  #'12)'-like\n",
        "                        temp = t.split('\\n')[0].strip().split('(')[0].split(')')[0].strip()\n",
        "                        if temp[0] in '1234567890':\n",
        "                            number = re.sub(r'[a-z]', '', temp)\n",
        "                            if re.findall(r'[a-z]', temp) != 0:\n",
        "                                letter = re.sub(r'\\d', '', temp)\n",
        "                        else: #'a)'-like\n",
        "                            letter = temp\n",
        "                    elif t.split('\\n')[0].strip().split(':')[0].strip().isdigit(): #'12:'-like\n",
        "                        number = t.split('\\n')[0].strip().split(':')[0].strip()\n",
        "                    elif t.strip()[1] == '.': #'b.'-like\n",
        "                        letter = t.split('\\n')[0].strip().strip('.').split('.')[0]\n",
        "                        letter = letter.strip()\n",
        "                    elif t.split('\\n')[0].strip().split('.')[0].strip()[0].isdigit(): #'12.'-like\n",
        "                        number = t.split('\\n')[0].strip().split('.')[0].strip()\n",
        "                    if number and (str(number) + '_' + str(p + 1)) not in examples_dic:\n",
        "                        examples_dic[str(number) + '_' + str(p + 1)] = []\n",
        "                    # cleaning from number-letters\n",
        "                    txt = re.sub(r'((\\(?(\\d+([\\.\\-:]\\d+){0,2}|\\d*[a-z])\\)|\\d+:|\\[\\d+\\]|\\d+([a-z]|\\-\\d+)?\\.)(\\s+?[a-z]\\.|\\s+?\\([a-z]\\))?)|(\\s*?[a-z]\\.)', '', t)\n",
        "                    clear = txt.split('\\n')\n",
        "                    for i in range(len(clear)):\n",
        "                        line = clear[i]\n",
        "                        if '-' not in line and '=' not in line and '–' not in line and '+' not in line:\n",
        "                            continue\n",
        "                        else:\n",
        "                            break\n",
        "                    txt = '\\n'.join(clear[i:])\n",
        "                    txt = txt.strip().split('\\n')\n",
        "                    if len(txt) == 5:  # two first rows are four\n",
        "                        txt[0] = re.sub(r'^[a-z]\\.', '', txt[0].strip())\n",
        "                        txt[0] = re.sub(r'^[a-z]\\)', '', txt[0].strip())\n",
        "                        original = ''\n",
        "                        gloss = ''\n",
        "                        trans = txt[-1].strip()\n",
        "                        for i in txt[:-1:2]:\n",
        "                            original += i.strip() + ' '\n",
        "                        for i in txt[1:-1:2]:\n",
        "                            gloss += i.strip() + ' '\n",
        "                    elif len(txt) == 4:  # first row to omit\n",
        "                        txt[1] = re.sub(r'^[a-z]\\.', '', txt[1].strip())\n",
        "                        txt[1] = re.sub(r'^[a-z]\\)', '', txt[1].strip())\n",
        "                        original = txt[1].strip()\n",
        "                        gloss = txt[2].strip()\n",
        "                        trans = txt[-1].strip()\n",
        "                    elif len(txt) == 3:  # three rows, everything OK\n",
        "                        txt[0] = re.sub(r'^[a-z]\\.', '', txt[0].strip())\n",
        "                        txt[0] = re.sub(r'^[a-z]\\)', '', txt[0].strip())\n",
        "                        original = txt[0].strip()\n",
        "                        gloss = txt[1].strip()\n",
        "                        trans = txt[-1].strip()\n",
        "                    # write to dictionary\n",
        "                    if letter and number and {letter: [original, gloss, trans]} not in examples_dic[str(number) + '_' + str(p + 1)]:\n",
        "                        examples_dic[str(number) + '_' + str(p + 1)].append({letter: [original, gloss, trans]})\n",
        "                    elif number and original and gloss and trans and [original, gloss, trans] not in examples_dic[str(number) + '_' + str(p + 1)]:\n",
        "                        examples_dic[str(number) + '_' + str(p + 1)].append([original, gloss, trans])\n",
        "    with open(path + '/' + name.split('.')[0] + '.json', 'w', encoding='utf-8') as fp:  # dictionary to JSON\n",
        "        json.dump(examples_dic, fp, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "O5kFCNGFnhlh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettify(text):  # function to clear lines from punctuation\n",
        "    w = text.strip('. ?!')\n",
        "    w = re.sub('\\\\t', ' ', w)\n",
        "    w = re.sub('\\t', ' ', w)\n",
        "    w = re.sub(r'–', '-', w)\n",
        "    w = re.sub(r'--', '-', w)\n",
        "    w = re.sub(r'\\s+-', '-', w)\n",
        "    w = re.sub(r'\\s+=', '=', w)\n",
        "    w = re.sub(r'=\\s+', '=', w)\n",
        "    w = re.sub(r'-\\s+', '-', w)\n",
        "    w = re.sub(r'--', '-', w)\n",
        "    w = re.sub(r'\\(.\\)', '', w)\n",
        "    w_new = re.sub(r'\\[|\\]', '', w)\n",
        "    w_new = re.sub(r'\\s{2,}', ' ', w_new)\n",
        "    w_new = w_new.split()\n",
        "    return w, w_new"
      ],
      "metadata": {
        "id": "lRVOXmestUEz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FpPdZx4wVXwF"
      },
      "outputs": [],
      "source": [
        "def glossing(name):  # cutting into morphemes\n",
        "    l = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ.n/123():\\\\sgplmfn>'  # allowed signs  for a gloss\n",
        "    list_of_glosses = {}\n",
        "    path = name.split('.')[0]\n",
        "    with open(path + '/' + name.split('.')[0] + '.json', encoding='utf-8') as file:  # examples' loading\n",
        "        dic = json.load(file)\n",
        "    for it in dic:\n",
        "        items = dic[it]\n",
        "        for item in items:\n",
        "            if type(item) != list:\n",
        "                item = list(item.values())[0]\n",
        "            words, words_new = prettify(item[0])\n",
        "            glossed_words, glossed_words_new = prettify(item[1])\n",
        "            if len(words_new) != len(glossed_words_new):  # not equal number of words\n",
        "                # try to delete everything inside square brackets \n",
        "                words = re.sub(r'\\[.*?\\]', '', words)  \n",
        "                words = re.sub(r'\\s{2,}', ' ', words)\n",
        "                words = words.split()\n",
        "                glossed_words = re.sub(r'\\[.*?\\]', '', glossed_words)\n",
        "                glossed_words = re.sub(r'\\s{2,}', ' ', glossed_words)\n",
        "                glossed_words = glossed_words.split()\n",
        "            else:\n",
        "                glossed_words = glossed_words_new\n",
        "                words = words_new\n",
        "            if len(words) == len(glossed_words):  # equal number of words\n",
        "                for index in range(len(words)):\n",
        "                    # split by dividers\n",
        "                    word = re.split(r'-|=|~', words[index].strip())  \n",
        "                    glossed_word = re.split(r'-|=|~', glossed_words[index].strip())\n",
        "                    if len(word) == len(glossed_word):  # equal number of parts\n",
        "                        for i in range(len(glossed_word)):\n",
        "                            gloss = glossed_word[i]\n",
        "                            flag = 0\n",
        "                            for letter in gloss:\n",
        "                                if letter not in l:\n",
        "                                    flag = 1\n",
        "                            if flag == 0:  # check if all the signs are allowed\n",
        "                                # clear from punctuation\n",
        "                                if ')' in gloss and '(' not in gloss:\n",
        "                                    gloss = gloss.strip(')')\n",
        "                                affix = word[i].lower().strip('#[]*)(….?”!/,!1234567890<>|/')\n",
        "                                affix = affix.split('(')[0]\n",
        "                                affix = affix.split('/')[0]\n",
        "                                affix = affix.strip('#[]*)(….?”!/,!1234567890<>|/')\n",
        "                                gloss = re.sub(r'\\(|\\)', '', gloss).upper().strip('.')\n",
        "                                # write to dictionary\n",
        "                                if gloss and gloss not in list_of_glosses and affix:  \n",
        "                                    list_of_glosses[gloss] = [{affix: [it]}]\n",
        "                                elif gloss and affix:\n",
        "                                    flag = 0\n",
        "                                    for affixes in list_of_glosses[gloss]:\n",
        "                                        if affix in affixes.keys():\n",
        "                                            flag = 1\n",
        "                                    if flag == 0:\n",
        "                                        list_of_glosses[gloss].append({affix: [it]})\n",
        "                                    else:\n",
        "                                        for affixes in list_of_glosses[gloss]: \n",
        "                                            if affix in affixes.keys() and it not in affixes[affix]:\n",
        "                                                affixes[affix].append(it)\n",
        "    with open(path + '/' + name.split('.')[0] + '_glosses.json', 'w', encoding='utf-8') as f:  # dictionary to JSON\n",
        "        json.dump(list_of_glosses, f, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def web_glosses():  # function to upload glosses with keywords from Wiki\n",
        "    html = requests.get('https://en.wiktionary.org/wiki/Appendix:List_of_glossing_abbreviations')\n",
        "    content =  html.text\n",
        "    # searchin in HTML\n",
        "    glosses = re.findall('<td><small>(.+?)<\\/small><\\/td>\\n<td>(((.*?)<a.*>(.+?)<\\/a>(.*))|(.*?))\\n', content)\n",
        "    web_dic_glosses = {}\n",
        "    for item in glosses:\n",
        "        name = ''\n",
        "        if item[4] != '':\n",
        "            if item[5] != '':\n",
        "                name = re.findall('<small>(.*?)</small>', item[5])\n",
        "            if not item[4].startswith('('):\n",
        "                text = item[4].split('(')[0].strip().strip(string.punctuation)\n",
        "            else:\n",
        "                text = item[4].split(')')[1].strip()\n",
        "        elif item[1] != '':\n",
        "            text = item[1].split('(')[0].strip().strip(string.punctuation)\n",
        "        n = item[0].split(',')\n",
        "        if len(n) > 1:\n",
        "            for i in n:\n",
        "                i = i.strip()\n",
        "                if '(' in i and i not in web_dic_glosses:\n",
        "                    web_dic_glosses[i.split('(')[0]] = text\n",
        "                    name = i.replace('(', '')\n",
        "                    name = name.replace(')', '')\n",
        "                if i not in web_dic_glosses:\n",
        "                    web_dic_glosses[i] = text\n",
        "        elif text and '(' in item[0] and item[0] not in web_dic_glosses:\n",
        "            web_dic_glosses[item[0].split('(')[0]] = text\n",
        "            name = item[0].replace('(', '')\n",
        "            name = name.replace(')', '')\n",
        "        elif text and item[0] not in web_dic_glosses:\n",
        "            web_dic_glosses[item[0]] = text\n",
        "        if text and name and name[0] not in web_dic_glosses:\n",
        "            web_dic_glosses[name[0]] = text\n",
        "    # deleting excessive ones (may be added as well)\n",
        "    del web_dic_glosses['V']\n",
        "    del web_dic_glosses['SG']\n",
        "    del web_dic_glosses['PL']\n",
        "    del web_dic_glosses['DU']\n",
        "    del web_dic_glosses['IN']\n",
        "    del web_dic_glosses['AGR']\n",
        "    del web_dic_glosses['FORM']\n",
        "    del web_dic_glosses['A']\n",
        "    del web_dic_glosses['HIST']\n",
        "    del web_dic_glosses['B']\n",
        "    del web_dic_glosses['AND']\n",
        "    del web_dic_glosses['PP']\n",
        "    del web_dic_glosses['PPFV']\n",
        "    return web_dic_glosses"
      ],
      "metadata": {
        "id": "9ClALtIJM0f0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def table_glossing(name):  # searching morphemes in tables\n",
        "    dic_glosses = web_glosses()\n",
        "    path = name.split('.')[0]\n",
        "    list_of_items = os.listdir(path)  # every file in folder\n",
        "    with open(path + '/' + name.split('.')[0] + '_glosses.json', encoding='utf-8') as file:  # dictionary with examples' glosses\n",
        "        dic = json.load(file)\n",
        "    dic_of_glosses = {}\n",
        "    for gloss in dic:\n",
        "        for it in dic[gloss]:\n",
        "            if list(it.keys())[0] not in dic_of_glosses:\n",
        "                dic_of_glosses[list(it.keys())[0]] = [gloss]\n",
        "            elif gloss not in dic_of_glosses[list(it.keys())[0]]:\n",
        "                dic_of_glosses[list(it.keys())[0]].append(gloss)\n",
        "    keyss = list(web_glosses().keys())  # list of glosses from Wiki\n",
        "    valuess = [w.split(' ')[0] for w in web_glosses().values()] # list of keywords for glosses from Wiki\n",
        "    for item in list_of_items:\n",
        "        if item.endswith('.csv') and item[0].isdigit():  # each .csv file\n",
        "            num = item.split('._')[0]  # number + page\n",
        "            with open(path + '/' + item) as csv_file:\n",
        "                tablereader = csv.reader(csv_file)\n",
        "                try:\n",
        "                    names = list(tablereader)[0]  # first row (columns' names)\n",
        "                    for i in range(len(names)):\n",
        "                        if re.findall(r'\\w+[\\-–]\\s?\\n\\w+', names[i]):  # check if line wrapping\n",
        "                            new_word = re.sub(r'[\\-–]\\s?\\n', '', re.findall(r'\\w+[\\-–]\\s?\\n\\w+', names[i])[0])\n",
        "                            if d_en.check(new_word) or d_de.check(new_word) or d_fr.check(new_word) or d_es.check(new_word):  # if word exists in English, French, German or Spanish\n",
        "                                names[i] = re.sub(r'[\\-–]\\s?\\n', '', names[i])  # line wrapping\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "            with open(path + '/' + item) as csv_file:\n",
        "                tablereader = csv.reader(csv_file)\n",
        "                for row in list(tablereader):\n",
        "                    for i in range(len(row)):\n",
        "                        words = row[i].strip()\n",
        "                        if re.findall(r'\\w+[\\-–]\\s?\\n\\w+', words):  # check if line wrapping\n",
        "                            new_word = re.sub(r'[\\-–]\\s?\\n', '', re.findall(r'\\w+[\\-–]\\s?\\n\\w+', words)[0])\n",
        "                            if d_en.check(new_word) or d_de.check(new_word) or d_fr.check(new_word) or d_es.check(new_word):  # if word exists in English, French, German or Spanish\n",
        "                                row[i] = re.sub(r'[\\-–]\\s?\\n', '', words)  # line wrapping\n",
        "                        words = re.split(r'\\s|\\/', row[i])\n",
        "                        for word in range(len(words)):\n",
        "                            w = words[word]\n",
        "                            # cleaning from punctuation\n",
        "                            w = w.strip(',:;')\n",
        "                            w = w.replace('(', '')\n",
        "                            w = w.replace(')', '').strip()\n",
        "                            # check if dividers in the end/beginning\n",
        "                            if w.startswith('-') or w.startswith('–') or w.startswith('=') or w.endswith('-') or w.endswith('–') or w.endswith('='):\n",
        "                                w = w.strip(string.punctuation)\n",
        "                                w = w.strip('–')\n",
        "                                if '-' not in w and '–' not in w and '=' not in w and w.islower():  # not a fully glossed example \n",
        "                                    f = 0\n",
        "                                    if w in dic_of_glosses.keys() and len(dic_of_glosses[w]) != 1:  # if already exists in dictionary\n",
        "                                        if names[i].strip() == '' and i != 0:\n",
        "                                            names[i] = names[i - 1]\n",
        "                                        if i == 0:\n",
        "                                            # first item: definitions in column and cell\n",
        "                                            defs = names[i] + ' ' + ' '.join(words[:word]) + ' ' + ' '.join(words[word + 1:]) + ' ' + ' '.join(row[i + 1:])\n",
        "                                        else:\n",
        "                                            # not first: definitions in row, column and cell\n",
        "                                            defs = names[i] + ' ' + row[0] + ' ' + ' '.join(words[:word]) + ' ' + ' '.join(words[word + 1:]) + ' ' + ' '.join(row[i + 1:])\n",
        "                                        # try to find person marking\n",
        "                                        person = re.findall(r'(\\d)[^\\s]*?\\s?([^\\s]*?)\\s?((s(in)?g|pl|du)(.*)|(s|p|d)(\\s|$))', defs.lower())\n",
        "                                        if person:\n",
        "                                            if person[0][2].startswith('s'):\n",
        "                                                number = 'SG'\n",
        "                                            elif person[0][2].startswith('d'):\n",
        "                                                number = 'DU'\n",
        "                                            else:\n",
        "                                                number = 'PL'\n",
        "                                            key = person[0][0].strip() + number\n",
        "                                            if key in dic_of_glosses[w]:\n",
        "                                                for it in dic[key]:\n",
        "                                                    if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                        it[w].append('TAB. ' + num)\n",
        "                                                        break\n",
        "                                            else:\n",
        "                                                if key in dic.keys():\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                            f = 1\n",
        "                                                            break\n",
        "                                                    if f == 0:\n",
        "                                                        dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                else:\n",
        "                                                    dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                            continue\n",
        "                                        # try to find noun class marking\n",
        "                                        gender = re.findall(r'\\b\\d|\\b[IV]+\\b', defs)\n",
        "                                        if gender and len(gender) == 1:\n",
        "                                            gender = gender[0]\n",
        "                                            person = re.findall(r'\\b((s(in)?g|pl|du)(.*)|(s|p|d)(\\s|$))', defs.lower())\n",
        "                                            if person:\n",
        "                                                if person[0][1].startswith('s'):\n",
        "                                                    number = 'SG'\n",
        "                                                elif person[0][1].startswith('d'):\n",
        "                                                    number = 'DU'\n",
        "                                                else:\n",
        "                                                    number = 'PL'\n",
        "                                                key = gender + number\n",
        "                                                if key in dic_of_glosses[w]:\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                            break\n",
        "                                                else:\n",
        "                                                    if key in dic.keys():\n",
        "                                                        for it in dic[key]:\n",
        "                                                            if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                                it[w].append('TAB. ' + num)\n",
        "                                                                f = 1\n",
        "                                                                break\n",
        "                                                        if f == 0:\n",
        "                                                            dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                    else:\n",
        "                                                        dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                                continue\n",
        "                                        defs = defs.split()\n",
        "                                        flag = 0\n",
        "                                        for d in defs:  # try to find in Wiki-glosses\n",
        "                                            d = d.strip(';:,.()')\n",
        "                                            if d.lower() in valuess:  # keyword\n",
        "                                                flag = 1\n",
        "                                                index = valuess.index(d.lower())\n",
        "                                                key = keyss[index]\n",
        "                                                if key in dic_of_glosses[w]:\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                else:\n",
        "                                                    if key in dic.keys():\n",
        "                                                        for it in dic[key]:\n",
        "                                                            if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                                it[w].append('TAB. ' + num)\n",
        "                                                                f = 1\n",
        "                                                        if f == 0:\n",
        "                                                            dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                    else:\n",
        "                                                        dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                            elif d.upper() in keyss:  # gloss\n",
        "                                                flag = 1\n",
        "                                                key = d.upper()\n",
        "                                                if key in dic_of_glosses[w]:\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                else:\n",
        "                                                    if key in dic.keys():\n",
        "                                                        for it in dic[key]:\n",
        "                                                            if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                                it[w].append('TAB. ' + num)\n",
        "                                                                f = 1\n",
        "                                                        if f == 0:\n",
        "                                                            dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                    else:\n",
        "                                                        dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                            if flag == 1:\n",
        "                                                break\n",
        "                                        if flag == 0:  # not found -> append to each gloss\n",
        "                                            for key in dic_of_glosses[w]:\n",
        "                                                for it in dic[key]:\n",
        "                                                    if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                        it[w].append('TAB. ' + num)\n",
        "                                    elif w in dic_of_glosses.keys() and len(dic_of_glosses[w]) == 1:  # only one gloss -> append\n",
        "                                        for it in dic[dic_of_glosses[w][0]]:\n",
        "                                            if list(it.keys())[0] == w and 'TAB. ' + num not in it[w]:\n",
        "                                                it[w].append('TAB. ' + num)\n",
        "                                    else:  # not in dictionary\n",
        "                                        if i == 0:\n",
        "                                            # first item: definitions in column and cell\n",
        "                                            defs = names[i] + ' ' + ' '.join(words[:word]) + ' ' + ' '.join(words[word + 1:]) + ' ' + ' '.join(row[i + 1:])\n",
        "                                        else:\n",
        "                                            # not first: definitions in row, column and cell\n",
        "                                            defs = names[i] + ' ' + row[0] + ' ' + ' '.join(words[:word]) + ' ' + ' '.join(words[word + 1:]) + ' ' + ' '.join(row[i + 1:])\n",
        "                                        # try to find person marking\n",
        "                                        person = re.findall(r'(\\d)[^\\s]*?\\s?([^\\s]*?)\\s?((s(in)?g|pl|du)(.*)|(s|p|d)(\\s|$))', defs.lower())\n",
        "                                        if person:\n",
        "                                            if person[0][2].startswith('s'):\n",
        "                                                number = 'SG'\n",
        "                                            elif person[0][2].startswith('d'):\n",
        "                                                number = 'DU'\n",
        "                                            else:\n",
        "                                                number = 'PL'\n",
        "                                            key = person[0][0].strip() + number\n",
        "                                            if key in dic.keys():\n",
        "                                                for it in dic[key]:\n",
        "                                                    if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                        it[w].append('TAB. ' + num)\n",
        "                                                        f = 1\n",
        "                                                        break\n",
        "                                                if f == 0:\n",
        "                                                    dic[key].append({w: ['TAB. ' + num]})\n",
        "                                            else:\n",
        "                                                dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                            continue\n",
        "                                        # try to find noun class marking\n",
        "                                        gender = re.findall(r'\\b\\d|\\b[IV]+\\b', defs)\n",
        "                                        if gender and len(gender) == 1:\n",
        "                                            gender = gender[0]\n",
        "                                            person = re.findall(r'\\b((s(in)?g|pl|du)(.*)|(s|p|d)(\\s|$))', defs.lower())\n",
        "                                            if person:\n",
        "                                                if person[0][1].startswith('s'):\n",
        "                                                    number = 'SG'\n",
        "                                                elif person[0][1].startswith('d'):\n",
        "                                                    number = 'DU'\n",
        "                                                else:\n",
        "                                                    number = 'PL'\n",
        "                                                key = gender + number\n",
        "                                                if key in dic.keys():\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                            f = 1\n",
        "                                                            break\n",
        "                                                    if f == 0:\n",
        "                                                        dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                else:\n",
        "                                                    dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                                continue\n",
        "                                        defs = defs.split()\n",
        "                                        for d in defs:  # try to find in Wiki-glosses\n",
        "                                            d = d.strip(';:,.()')\n",
        "                                            if d.lower() in valuess:  # keyword\n",
        "                                                index = valuess.index(d.lower())\n",
        "                                                key = keyss[index]\n",
        "                                                if key in dic.keys():\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                            f = 1\n",
        "                                                            break\n",
        "                                                    if f == 0:\n",
        "                                                        dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                else:\n",
        "                                                    dic[key] = [{w: ['TAB. ' + num]}]\n",
        "                                            elif d.upper() in keyss:  # gloss\n",
        "                                                flag = 1\n",
        "                                                key = d.upper()\n",
        "                                                if key in dic.keys():\n",
        "                                                    for it in dic[key]:\n",
        "                                                        if w in it.keys() and 'TAB. ' + num not in it[w]:\n",
        "                                                            it[w].append('TAB. ' + num)\n",
        "                                                            f = 1\n",
        "                                                            break\n",
        "                                                    if f == 0:\n",
        "                                                        dic[key].append({w: ['TAB. ' + num]})\n",
        "                                                else:\n",
        "                                                    dic[key] = [{w: ['TAB. ' + num]}]\n",
        "    with open(path + '/' + name.split('.')[0] + '_all_glosses.json', 'w', encoding='utf-8') as f:  # dictionary to JSON\n",
        "        json.dump(dic, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "TGbnR4bwkczq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nxoSpMOYZlWL"
      },
      "outputs": [],
      "source": [
        "def beautify_glosses(name):  # glosses to table\n",
        "    path = name.split('.')[0]\n",
        "    with open(path + '/' + name.split('.')[0] + '_all_glosses.json', encoding='utf-8') as file:  # open JSON\n",
        "        dic = json.load(file)\n",
        "        dic = dict(sorted(dic.items()))\n",
        "    df = pd.DataFrame(columns=['Gloss', 'Affix', 'Examples'])  # create table\n",
        "    for gloss in dic:\n",
        "        for pair in dic[gloss]:\n",
        "            for key in list(pair.keys()):\n",
        "                affix = '-' + key + '-'\n",
        "                examples = ''\n",
        "                for i in range(len(pair[key])):\n",
        "                    tab = 0\n",
        "                    if pair[key][i].startswith('TAB.'):  # if it's table entry\n",
        "                        page, example = pair[key][i].split()[1].split('_')\n",
        "                        tab = 1\n",
        "                    else:  # if it's example entry\n",
        "                        example, page = pair[key][i].split('_')\n",
        "                    if i == 0 and i == len(pair[key]) - 1:\n",
        "                        # beautifying list of examples and tables\n",
        "                        if tab == 1:\n",
        "                            examples += 'p. ' + page + ' tab. (' + example + ')'\n",
        "                        else:\n",
        "                            examples += 'p. ' + page + ' (' + example + ')'\n",
        "                    elif i == 0:\n",
        "                        if tab == 1:\n",
        "                            examples += 'p. ' + page + ' tab. (' + example + ')'\n",
        "                        else:\n",
        "                            examples += 'p. ' + page + ' (' + example + ')'\n",
        "                    elif i == len(pair[key]) - 1:\n",
        "                        if tab == 1:\n",
        "                            examples += ', p. ' + page + ' tab. (' + example + ')'\n",
        "                        else:\n",
        "                            examples += ', p. ' + page + ' (' + example + ')'\n",
        "                    else:\n",
        "                        if tab == 1:\n",
        "                            examples += ', p. ' + page + ' tab. (' + example + ')'\n",
        "                        else:\n",
        "                            examples += ', p. ' + page + ' (' + example + ')'\n",
        "                # add to table\n",
        "                df = pd.concat([df, pd.DataFrame([[gloss, affix, examples], ], columns=['Gloss', 'Affix', 'Examples'])], ignore_index=True)\n",
        "    # drop duplicates\n",
        "    df = df.drop_duplicates().reset_index().drop(columns=['index'])\n",
        "    df.to_csv(path + '/' + name.split('.')[0] + '_glosses.csv')  # to CSV\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VLY_5PdNjSe0"
      },
      "outputs": [],
      "source": [
        "def beautify_examples(name):  # examples to table\n",
        "    path = name.split('.')[0]\n",
        "    with open(path + '/' + name.split('.')[0] + '.json', encoding='utf-8') as file:  # open JSON\n",
        "        dic = json.load(file)\n",
        "        dic = dict(sorted(dic.items()))\n",
        "    df = pd.DataFrame(columns=['Number_Example', 'Page', 'Example', 'Glossing', 'Translation'])  # create table\n",
        "    for number in dic:\n",
        "        example, page = number.split('_')  # number and page\n",
        "        for pair in dic[number]:\n",
        "            if type(pair) == list and len(pair) == 3:  # 3 lines\n",
        "                words, words_new = prettify(pair[0])\n",
        "                glossed_words, glossed_words_new = prettify(pair[1])\n",
        "                if len(words_new) != len(glossed_words_new):  # not equal number of words\n",
        "                    # try to delete everything inside square brackets \n",
        "                    words = re.sub(r'\\[.*?\\]', '', words)\n",
        "                    words = re.sub(r'\\s{2,}', ' ', words)\n",
        "                    words = words.split()\n",
        "                    glossed_words = re.sub(r'\\[.*?\\]', '', glossed_words)\n",
        "                    glossed_words = re.sub(r'\\s{2,}', ' ', glossed_words)\n",
        "                    glossed_words = glossed_words.split()\n",
        "                else:\n",
        "                    glossed_words = glossed_words_new\n",
        "                    words = words_new\n",
        "                if len(words) == len(glossed_words):  # equal number of words\n",
        "                    words = ' '.join(words)\n",
        "                    glossed_words = ' '.join(glossed_words)\n",
        "                    # split by dividers\n",
        "                    word = re.split(r'\\s|-|=|~|<|>', words)\n",
        "                    glossed_word = re.split(r'\\s|-|=|~|<|>', glossed_words)\n",
        "                    if words.strip() and len(word) == len(glossed_word):  # write to table\n",
        "                        df = pd.concat([df, pd.DataFrame([[example, page, words, glossed_words, pair[2]], ], columns=['Number_Example', 'Page', 'Example', 'Glossing', 'Translation'])], ignore_index=True)\n",
        "            elif type(pair) == dict:\n",
        "                for key in list(pair.keys()):\n",
        "                    if len(pair[key]) == 3:  # 3 lines\n",
        "                        words, words_new = prettify(pair[key][0])\n",
        "                        glossed_words, glossed_words_new = prettify(pair[key][1])\n",
        "                        if len(words_new) != len(glossed_words_new):  # not equal number of words\n",
        "                            # try to delete everything inside square brackets \n",
        "                            words = re.sub(r'\\[.*?\\]', '', words)\n",
        "                            words = re.sub(r'\\s{2,}', ' ', words)\n",
        "                            words = words.split()\n",
        "                            glossed_words = re.sub(r'\\[.*?\\]', '', glossed_words)\n",
        "                            glossed_words = re.sub(r'\\s{2,}', ' ', glossed_words)\n",
        "                            glossed_words = glossed_words.split()\n",
        "                        else:\n",
        "                            glossed_words = glossed_words_new\n",
        "                            words = words_new\n",
        "                        if len(words) == len(glossed_words):  # equal number of words\n",
        "                            words = ' '.join(words)\n",
        "                            glossed_words = ' '.join(glossed_words)\n",
        "                            # split by dividers\n",
        "                            word = re.split(r'\\s|-|=|~|<|>', words)\n",
        "                            glossed_word = re.split(r'\\s|-|=|~|<|>', glossed_words)\n",
        "                            if words.strip() and len(word) == len(glossed_word):  # write to table\n",
        "                                df = pd.concat([df, pd.DataFrame([[example, str(page) + ' (' + key + ')', words, glossed_words, pair[key][2]], ], columns=['Number_Example', 'Page', 'Example', 'Glossing', 'Translation'])], ignore_index=True)\n",
        "    df = df.drop_duplicates().reset_index().drop(columns=['index'])\n",
        "    # drop duplicates\n",
        "    df.to_csv(path + '/' + name.split('.')[0] + '_examples.csv')  # to CSV\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_id = '1Hjfru6VSZWIyt2Gg6ZRRtvAeQrgmOM2GAi8LMT6whs0'  # Goofle Sheets with 1000 checked grammars\n",
        "sheet_name ='Sheet1'\n",
        "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
        "grammars = pd.read_csv(url)  # upload table\n",
        "grams = grammars[(grammars['да/нет'] == 'да')].sort_values(by='про какой язык')  # searchable ones"
      ],
      "metadata": {
        "id": "8mWFXf767Xly"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UPLOAD_FOLDER = os.getcwd()  # folder to upload\n",
        "app = Flask(__name__, static_url_path='/static')\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER"
      ],
      "metadata": {
        "id": "9T0NtdAeRvph"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/')  # starting page\n",
        "def index():\n",
        "    options = ''\n",
        "    for index, row in grams.iterrows():\n",
        "        # options from Google Sheets\n",
        "        options += '<option value=\"{}\">{}</option>\\n'.format(row['id'], row['полный путь'].split('/')[-1].split('.')[0])\n",
        "    return render_template('index.html', options = options, ID = row['id'])\n",
        "\n",
        "@app.route('/results', methods=['POST', 'GET'])  # resulting page\n",
        "def upload_route_summary():\n",
        "    if request.method == 'POST':  # submit file\n",
        "        file = request.files['fileupload']\n",
        "        filename = secure_filename(file.filename)\n",
        "        if not os.path.exists(filename.split('.')[0]):  # not in foler\n",
        "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "            extract_examples_tables(filename)\n",
        "            glossing(filename)\n",
        "            table_glossing(filename)\n",
        "            table1 = beautify_glosses(filename).to_html(justify='center', escape=False)\n",
        "            # change examples' numbers to links\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) \\((.+?)\\)\", r\"p. \\g<1> (<a href='/example?page=\\g<1>&example=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            # change tables' numbers to links\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) tab\\. \\((.+?)\\)\", r\"p. \\g<1> tab. (<a href='/table?page=\\g<1>&table=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table2 = beautify_examples(filename).to_html(justify='center', escape=False)\n",
        "            name = filename.split('.')[0] + '/' + filename.split('.')[0]\n",
        "        else:  # already in folder\n",
        "            table1 = beautify_glosses(filename).to_html(justify='center', escape=False)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) \\((.+?)\\)\", r\"p. \\g<1> (<a href='/example?page=\\g<1>&example=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) tab\\. \\((.+?)\\)\", r\"p. \\g<1> tab. (<a href='/table?page=\\g<1>&table=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table2 = beautify_examples(filename).to_html(justify='center', escape=False)\n",
        "            name = filename.split('.')[0] + '/' + filename.split('.')[0]\n",
        "    elif request.method == 'GET':  # submit one from Google Sheets or return\n",
        "        if request.args.get('filename'):  # returned one\n",
        "            filename = request.args.get('filename') + '.pdf'\n",
        "            table1 = beautify_glosses(filename).to_html(justify='center', escape=False)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) \\((.+?)\\)\", r\"p. \\g<1> (<a href='/example?page=\\g<1>&example=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) tab\\. \\((.+?)\\)\", r\"p. \\g<1> tab. (<a href='/table?page=\\g<1>&table=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table2 = beautify_examples(filename).to_html(justify='center', escape=False)\n",
        "            name = filename.split('.')[0] + '/' + filename.split('.')[0]\n",
        "        elif request.args.get('vars'):  # submitted from Google Sheets\n",
        "            ID = request.args.get('vars')\n",
        "            url = 'https://drive.google.com/uc?id=' + ID  # ID in Google Drive\n",
        "            filename = 'file.pdf'\n",
        "            gdown.download(url, os.path.join(app.config['UPLOAD_FOLDER'], filename))  # download by ID from Google Drive\n",
        "            extract_examples_tables(filename)\n",
        "            glossing(filename)\n",
        "            table_glossing(filename)\n",
        "            table1 = beautify_glosses(filename).to_html(justify='center', escape=False)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) \\((.+?)\\)\", r\"p. \\g<1> (<a href='/example?page=\\g<1>&example=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table1 = re.sub(r\"p\\. (\\d+?) tab\\. \\((.+?)\\)\", r\"p. \\g<1> tab. (<a href='/table?page=\\g<1>&table=\\g<2>&filename={}'>\\g<2></a>)\".format(filename.split('.')[0]), table1)\n",
        "            table2 = beautify_examples(filename).to_html(justify='center', escape=False)\n",
        "            name = filename.split('.')[0] + '/' + filename.split('.')[0]\n",
        "    return render_template('data.html', table1 = table1, table2 = table2, name = name)\n",
        "\n",
        "\n",
        "@app.route('/download', methods=['GET'])  # download data\n",
        "def downloadFile():\n",
        "    if not request.args:\n",
        "        return redirect(url_for('/results'))\n",
        "    table = request.args.get('vars')\n",
        "    if table.endswith('.csv'):  # CSV-table\n",
        "        return send_file(table, as_attachment=True)\n",
        "    elif table.endswith('.jpeg'):  # ZIP of tables in .jpeg and .csv\n",
        "        t = table.split('/')[0]\n",
        "        with ZipFile(table + '_tables.zip', 'w') as zipObj:\n",
        "            for file in os.listdir(path=t + '/'):\n",
        "                if file.endswith('.jpeg') or (file.endswith('.csv') and file[0].isdigit()):\n",
        "                    zipObj.write(t + '/' + file)\n",
        "        return send_file(table + '_tables.zip', as_attachment=True)\n",
        "    else:  # the whole ZIP\n",
        "        t = table.split('/')[0]\n",
        "        with ZipFile(table + '.zip', 'w') as zipObj:\n",
        "            zipObj.write(table + '_glosses.csv')\n",
        "            zipObj.write(table + '_examples.csv')\n",
        "            for file in os.listdir(path=t + '/'):\n",
        "                if file.endswith('.jpeg') or (file.endswith('.csv') and file[0].isdigit()):\n",
        "                    zipObj.write(t + '/' + file)\n",
        "        return send_file(table + '.zip', as_attachment=True)\n",
        "\n",
        "@app.route('/example', methods=['GET'])  # link to example\n",
        "def showExample():\n",
        "    if not request.args:\n",
        "        return redirect(url_for('/results'))\n",
        "    page = request.args.get('page')\n",
        "    example = request.args.get('example')\n",
        "    filename = request.args.get('filename')\n",
        "    table2 = beautify_examples(filename + '.pdf')\n",
        "    # find example by page and number and convert to HTML\n",
        "    table2 = table2.loc[(table2['Page'] == page) & (table2['Number_Example'] == example)].to_html(justify='center', escape=False)\n",
        "    table1 = beautify_glosses(filename + '.pdf')\n",
        "    # find pairs with this example and convert to HTML\n",
        "    table1 =  table1[table1['Examples'].str.contains('p. {} ({})'.format(page, example), regex=False)].to_html(justify='center', escape=False)\n",
        "    return render_template('examples.html', table2 = table2, table1 = table1, filename = filename)\n",
        "\n",
        "@app.route('/table', methods=['GET'])  # link to table\n",
        "def showTable():\n",
        "    if not request.args:\n",
        "        return redirect(url_for('/results'))\n",
        "    page = request.args.get('page')\n",
        "    tab = request.args.get('table')\n",
        "    filename = request.args.get('filename')\n",
        "    for file in os.listdir(path=filename + '/'):\n",
        "        if file.startswith(page + '_' + tab):\n",
        "            if file.endswith('.jpeg'):\n",
        "                src_dir = filename + '/' + file\n",
        "                dst_dir = 'static'\n",
        "                shutil.copy(src_dir, dst_dir)  # copy image to static\n",
        "                image = file.replace(' ', '%20')\n",
        "    table1 = beautify_glosses(filename + '.pdf')\n",
        "    # find pairs with this table and convert to HTML\n",
        "    table1 =  table1[table1['Examples'].str.contains('p. {} tab. ({})'.format(page, tab), regex=False)].to_html(justify='center', escape=False)\n",
        "    return render_template('table.html', image = image, table1 = table1, filename = filename, page = page, tab = tab)"
      ],
      "metadata": {
        "id": "psAtCsw-R1Od"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    app.run(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GUzOFeR4_D",
        "outputId": "7d689985-d015-4ba1-db11-91ca91d90a39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AXfAC7AOR7ch"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "grammar-analysis.ipynb",
      "provenance": [],
      "mount_file_id": "1bBmtJ_e_Vk_H2dXVL6dgpMtIM3GU4yEz",
      "authorship_tag": "ABX9TyMGSgerr1xp9pSZ7bSsmKFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}